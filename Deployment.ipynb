{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b3ec4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing C:\\Users\\new\\sen_analyzer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:\\Users\\new\\sen_analyzer.py\n",
    "    \n",
    "#Importing Libraries:\n",
    "import streamlit as st \n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "st.set_page_config(page_title=\"App-Streamlit\",page_icon=\"random\",layout=\"wide\",\n",
    "                       menu_items={'Get Help': 'http://www.quickmeme.com/img/54/547621773e22705fcfa0e73bc86c76a05d4c0b33040fcb048375dfe9167d8ffc.jpg',\n",
    "                                   'Report a bug': \"https://w7.pngwing.com/pngs/839/902/png-transparent-ladybird-ladybird-bug-miscellaneous-presentation-insects-thumbnail.png\",\n",
    "                                   'About': \"# This is a Sentiment Analyser based on Amazon Reviews. Very Easy to use!\"})\n",
    "\n",
    "@st.cache(allow_output_mutation=True) #For Autoupdate in app.\n",
    "\n",
    "def loading_model():\n",
    "    model = load_model(r'C:\\Users\\new\\Documents\\PythonFiles\\EXCELR Project\\NLP project\\Main files\\lstm_model.h5')\n",
    "    return model\n",
    "with st.spinner('Model is being loaded..'):\n",
    "    model=loading_model()     #Model is loaded.\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Model Prediction func:\n",
    "def predict_bankruptcy(x):\n",
    "    pred=model.predict([[i,m,f,cr,co,o]])\n",
    "    prediction = (pred >=0.9995045) \n",
    "    prediction=1*prediction\n",
    "    print(prediction)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fb7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import contractions\n",
    "#from contractions import contractions_dict\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_review = normalize_and_lemmaize(review) # Cleaned text to predict\n",
    "onehot_=[one_hot(final_review,voc_size)] \n",
    "sent_length=30\n",
    "embedded_docs=pad_sequences(onehot_,padding='pre',maxlen=sent_length)\n",
    "X_predi=np.array(embedded_docs)\n",
    "a=model.predict(X_predi)\n",
    "Y_predi = (a >= 0.06263161) #optimal threshold is 0.06263161\n",
    "Y_predi=1*Y_predi \n",
    "if Y_predi == 1:\n",
    "    print(\"It is a good review\")\n",
    "elif Y_predi == 0:\n",
    "    print(\"It is a bad review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9c1cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\users\\new\\anaconda3\\lib\\site-packages (from flask) (7.1.2)\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->flask) (2.0.1)\n",
      "Installing collected packages: Werkzeug, Jinja2, itsdangerous, flask\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "Successfully installed Jinja2-3.0.3 Werkzeug-2.0.2 flask-2.0.2 itsdangerous-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426796dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\Users\\new\\sen_analyzer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:\\Users\\new\\sen_analyzer.py\n",
    "# Importing essential libraries\n",
    "from flask import Flask, render_template, request\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "def processing(review):\n",
    "    final_review = normalize_and_lemmaize(review) # Cleaned text to predict\n",
    "    onehot_=[one_hot(final_review,voc_size)] \n",
    "    sent_length=30\n",
    "    embedded_docs=pad_sequences(onehot_,padding='pre',maxlen=sent_length)\n",
    "    X_predi=np.array(embedded_docs)\n",
    "    return X_predi\n",
    "\n",
    "def prediction(vect):\n",
    "    temp=model.predict(X_predi)\n",
    "    Y_predi = (temp >= 0.06263161) #optimal threshold is 0.06263161\n",
    "    Y_predi=1*Y_predi \n",
    "    if Y_predi == 1:\n",
    "        print(\"It is a good review\")\n",
    "    elif Y_predi == 0:\n",
    "        print(\"It is a bad review\")\n",
    "    \n",
    "    \n",
    "# Load the Lstm model object from disk\n",
    "model = load_model(r'C:\\Users\\new\\Documents\\PythonFiles\\EXCELR Project\\NLP project\\Main files\\lstm_model.h5')\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "\treturn render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "    \tmessage = request.form['message']\n",
    "    \tdata = [message]\n",
    "    \tvect = processing(data)\n",
    "    \tmy_prediction = prediction(vect)\n",
    "    \treturn render_template('result.html', prediction=my_prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tapp.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd562827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
